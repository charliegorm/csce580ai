model,accuracy,precision,recall,f1,train_wall_time_sec,test_infer_time_sec
Logistic Regression,0.8908,0.8798600311041991,0.9052,0.8923501577287066,,
DistilBERT (finetuned),0.7999,0.7853472882968602,0.8254,0.8048756704046807,180.57693099975586,143.6395299434662
DistilBERT (base),0.4993,0.49964877069744107,0.9958,0.6654193117273638,,159.6229681968689
GPT-2,0.786,0.7411467116357504,0.879,0.8042086001829826,,17523.141612052917
